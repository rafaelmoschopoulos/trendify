{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello everyone :-). This is an exmple text that i wrote and that i'm going to use to test text preprocessing. www.google.com imho this is awsome brb 6542 h8 test@gmail.com\"\n",
    "text = text.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert emojis and emoticons to their desciption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone Happy face smiley. this is an exmple text that i wrote and that i'm going to use to test text preprocessing. www.google.com imho this is awsome brb 6542 h8 test@gmail.com\n"
     ]
    }
   ],
   "source": [
    "from emoticons import EMOTICONS_EMO as EMOTICONS\n",
    "for emot, meaning in EMOTICONS.items():\n",
    "    text = text.replace(emot, meaning)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone Happy face smiley. this is an exmple text that i wrote and that i'm going to use to test text preprocessing. www.google.com imho this is awsome brb 6542 h8 test@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "text = emoji.demojize(text).replace(\":\", \"\").replace(\"_\", \" \")\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert slang/chat words to actual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'afaik': 'as far as i know', 'afk': 'away from keyboard', 'asap': 'as soon as possible', 'atk': 'at the keyboard', 'atm': 'at the moment', 'a3': 'anytime, anywhere, anyplace', 'bak': 'back at keyboard', 'bbl': 'be back later', 'bbs': 'be back soon', 'bfn': 'bye for now', 'b4n': 'bye for now', 'brb': 'be right back', 'brt': 'be right there', 'btw': 'by the way', 'b4': 'before', 'cu': 'see you', 'cul8r': 'see you later', 'cya': 'see you', 'faq': 'frequently asked questions', 'fc': 'fingers crossed', 'fwiw': \"for what it's worth\", 'fyi': 'for your information', 'gal': 'get a life', 'gg': 'good game', 'gn': 'good night', 'gmta': 'great minds think alike', 'gr8': 'great!', 'g9': 'genius', 'ic': 'i see', 'icq': 'i seek you', 'ilu': 'ilu: i love you', 'imho': 'in my honest opinion', 'imo': 'in my opinion', 'iow': 'in other words', 'irl': 'in real life', 'kiss': 'keep it simple, stupid', 'ldr': 'long distance relationship', 'lmao': 'laugh my ass off', 'lol': 'laughing out loud', 'ltns': 'long time no see', 'l8r': 'later', 'mte': 'my thoughts exactly', 'm8': 'mate', 'nrn': 'no reply necessary', 'oic': 'oh i see', 'pita': 'pain in the ass', 'prt': 'party', 'prw': 'parents are watching', 'rofl': 'rolling on the floor laughing', 'roflol': 'rolling on the floor laughing out loud', 'rotflmao': 'rolling on the floor laughing my ass off', 'sk8': 'skate', 'stats': 'your sex and age', 'asl': 'age, sex, location', 'thx': 'thank you', 'ttfn': 'ta-ta for now!', 'ttyl': 'talk to you later', 'u': 'you', 'u2': 'you too', 'u4e': 'yours for ever', 'wb': 'welcome back', 'wtf': 'what the fuck', 'wtg': 'way to go!', 'wuf': 'where are you from?', 'w8': 'wait', '7k': 'sick', 'h8': 'hate'}\n",
      "hello everyone happy face smiley example text write go use test text reprocess honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "# This snippet must be run only once\n",
    "chat_words_str = \"\"\n",
    "with open('chatwords.txt', 'r') as chatwordsFile:\n",
    "    chat_words_str = chatwordsFile.read().lower()\n",
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "print(chat_words_map_dict)\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "new_text = []\n",
    "for w in text.split():\n",
    "    if w in chat_words_list:\n",
    "        new_text.append(chat_words_map_dict[w])\n",
    "    else:\n",
    "        new_text.append(w)\n",
    "text = \" \".join(new_text)\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand contractions. I.e. \"i'm\" -> \"i am\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text reprocess honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "text = contractions.fix(text)\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text reprocess honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "from cleantext import clean\n",
    "\n",
    "text = clean(text,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "    no_punct=True,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"\",\n",
    "    replace_with_email=\"\",\n",
    "    replace_with_phone_number=\"\",\n",
    "    replace_with_number=\"\",\n",
    "    replace_with_digit=\"\",\n",
    "    replace_with_currency_symbol=\"\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text process honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "corrected = []\n",
    "misspelled = spell.unknown(text.split())\n",
    "for word in text.split():\n",
    "    if word in misspelled:\n",
    "        corrected.append(spell.correction(word))\n",
    "    else:\n",
    "        corrected.append(word)\n",
    "text = \" \".join(corrected)\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text process honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization (convert each word to its root after finding the part of speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text process honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "pos_tagged_text = nltk.pos_tag(text.split())\n",
    "text = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello everyone happy face smiley example text write go use test text process honest opinion awesome right back hate\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = re.sub(' +', ' ', text)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
